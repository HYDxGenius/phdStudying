{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " enc_inputs: \n",
      " tensor([[1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 5, 0]])\n",
      " dec_inputs: \n",
      " tensor([[6, 1, 2, 3, 4, 8],\n",
      "        [6, 1, 2, 3, 5, 8]])\n",
      " dec_outputs: \n",
      " tensor([[1, 2, 3, 4, 8, 7],\n",
      "        [1, 2, 3, 5, 8, 7]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "# S: 起始标记\n",
    "# E: 结束标记\n",
    "# P：意为padding，将当前序列补齐至最长序列长度的占位符\n",
    "sentence = [\n",
    "    # enc_input   dec_input    dec_output\n",
    "    ['ich mochte ein bier P','S i want a beer .', 'i want a beer . E'],\n",
    "    ['ich mochte ein cola P','S i want a coke .', 'i want a coke . E'],\n",
    "]\n",
    " \n",
    "# 词典，padding用0来表示\n",
    "# 源词典\n",
    "src_vocab = {'P':0, 'ich':1,'mochte':2,'ein':3,'bier':4,'cola':5}\n",
    "src_vocab_size = len(src_vocab) # 6\n",
    "# 目标词典（包含特殊符）\n",
    "tgt_vocab = {'P':0,'i':1,'want':2,'a':3,'beer':4,'coke':5,'S':6,'E':7,'.':8}\n",
    "# 反向映射词典，idx ——> word (序号和对应的词)\n",
    "idx2word = {v:k for k,v in tgt_vocab.items()}\n",
    "tgt_vocab_size = len(tgt_vocab) # 9\n",
    " \n",
    "src_len = 5 # 输入序列enc_input的最长序列长度，其实就是最长的那句话的token数\n",
    "tgt_len = 6 # 输出序列dec_input/dec_output的最长序列长度\n",
    " \n",
    "# 构建模型输入的Tensor\n",
    "def make_data(sentence):\n",
    "    enc_inputs, dec_inputs, dec_outputs = [],[],[]\n",
    "    for i in range(len(sentence)):\n",
    "        enc_input = [src_vocab[word] for word in sentence[i][0].split()]\n",
    "        dec_input = [tgt_vocab[word] for word in sentence[i][1].split()]\n",
    "        dec_output = [tgt_vocab[word] for word in sentence[i][2].split()]\n",
    "        \n",
    "        enc_inputs.append(enc_input)\n",
    "        dec_inputs.append(dec_input)\n",
    "        dec_outputs.append(dec_output)\n",
    "        \n",
    "    # LongTensor是专用于存储整型的，Tensor则可以存浮点、整数、bool等多种类型\n",
    "    return torch.LongTensor(enc_inputs),torch.LongTensor(dec_inputs),torch.LongTensor(dec_outputs)\n",
    " \n",
    "enc_inputs, dec_inputs, dec_outputs = make_data(sentence)\n",
    " \n",
    "print(' enc_inputs: \\n', enc_inputs)  # enc_inputs: [2,5]\n",
    "print(' dec_inputs: \\n', dec_inputs)  # dec_inputs: [2,6]\n",
    "print(' dec_outputs: \\n', dec_outputs) # dec_outputs: [2,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
